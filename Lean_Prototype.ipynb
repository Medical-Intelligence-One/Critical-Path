{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc2bc56-5585-46e8-8252-4aaa5585d0fd",
   "metadata": {},
   "source": [
    "# Lean Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ca503-2195-4ac6-b496-947eb13dc6eb",
   "metadata": {},
   "source": [
    "Any graph should be modeled to suit the uses for which is was created, as far as they can be known. A knowledge graph is no different. In order to prepare training data for a transformer language model to extract knowledge from free text, we must have a model of our knowledge graph in mind. We must demonstrate consistent patterns for the language model to follow, and the output must be able to fit back into a useful graph. Here, we shall start at the end of that process to develop some simple rules of reasoning which will be able to use a knowledge graph to perform certain cognitive tasks. We shall assume that we can model our knowledge graph in any way that best suits our reasoning framework. Let us start with a few use cases.  \n",
    "  \n",
    "1. Given an observed association between a drug and a disease, generate an explanation for the association and hypothesize whether the drug causes the disease, treats it, or does neither. (First Data Bank FDB - used for EMR alerts - reports mild-moderate-severe interactions, but lacks causal direction and detail: e.g. MMR-Rhogam interaction is listed as severe, but you should increase dose of MMR, not omit it)\n",
    "2. Predict what other problems a patient is likely to experience given their current problem list, recommend how to prevent those comorbidities, and explain the predictions and recommendations. \n",
    "3. Show any close relationships among a given patient's problems at admission, highlight any causal chains among them, and identify any parts of the causal chain the patient is likely to have which are not yet reported in the EHR. Suggest a workup for these missing problems and what you would do to treat them. Check to see how often the discharge summary lists problems you identified as likely to be missing from the admission note. \n",
    "4. Show the typical course of any disease using both timedeltas and causal chains. Show where a given patient is in the course of the disease. If there are subgroups of patients who have different courses for the same disease, show which subgroup a given patient is in and what path (if any) leads from their current subgroup to a subgroup with better outcomes. \n",
    "5. For a patient with a given set of diseases, show how to maximize the timedelta between each of their problems and death. \n",
    "6. For drug-disease pairs that share an association in MIMIC-III but no known `treats` relationship in MED-RT, hypothesize why they are associated. In cases where the drug is hypothesized to cause the disease, identify any patients with instances of both the disease and the drug, and present the evidence for causation for review by a pharmacist or the ordering physician.\n",
    "7. Given a specific patient with a new diagnosis of atrial fibrillation, decide whether or not to anticoagulate and explain the recommendation. \n",
    "  \n",
    "Lean setup for a use-case:\n",
    "1. Generate a comprehensive knowledge graph for MIMIC-III.  \n",
    "    A. Search pubmed for articles about all of the problems, prescriptions, and abnormal labs found in MIMIC-III.  \n",
    "    B. Run all the articles through GPT3 to extract entities and relationships.  \n",
    "    C. Merge the entities and relationships into a graph that is pre-loaded with UMLS, MED-RT, RxNorm, and MeSH.  \n",
    "    D. Merge all entities in the patient data as instances of entities in the knowledge graph.   \n",
    "2. Develop a reasoning framework that can be used to fulfill use cases.  \n",
    "3. Iterate steps 1 and 2 to revise the knowledge model and reasoning framework until the use cases can be completed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41066f87-2e6f-4ac9-b98e-3211ebb76df3",
   "metadata": {},
   "source": [
    "## 1. Generate a comprehensive knowledge graph for MIMIC-III.\n",
    "### 1-A. Search pubmed for articles about all of the problems, prescriptions, and abnormal labs found in MIMIC-III. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "be523141-1403-4ece-83db-e07d4e4c0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import urllib.parse\n",
    "from datetime import datetime\n",
    "from progressbar import ProgressBar\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e02c0f4-1a08-4f01-a973-3f6e02deb34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please enter the Neo4j database password to continue \n",
      " ·······\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import time\n",
    "import re\n",
    "import pprint\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from multiprocessing import  Pool\n",
    "\n",
    "# Runing this cell will ask you to provide the database password. If you need the password, email Tim McLerran at tmclerran@gmail.com to provide evidence \n",
    "# that you have been granted access to MIMIC-III data by physionet. If you are unsure how to proceed, just ask the #nlp channel on Slack\n",
    "import getpass\n",
    "password = getpass.getpass(\"\\nPlease enter the Neo4j database password to continue \\n\")\n",
    "\n",
    "# Create a connection to the working group's Neo4j database of MIMIC-III data\n",
    "from neo4j import GraphDatabase\n",
    "driver=GraphDatabase.driver(uri=\"bolt://76.251.77.235:7687\", auth=('neo4j',password))\n",
    "session=driver.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28fa1440-4e58-445d-9ab2-9d6373fed2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search pubmed for articles about all of the problems, prescriptions, and abnormal labs found in MIMIC-III.\n",
    "\n",
    "# Define a function that takes a cypher query and returns a list-type result\n",
    "def get_list(query):\n",
    "    result = session.run(query)\n",
    "    entire_result = []\n",
    "    for record in result:\n",
    "        entire_result.append(record[0])\n",
    "    return entire_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3343f85e-3137-43a6-a39b-1e012feb7f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in list:  3250\n"
     ]
    }
   ],
   "source": [
    "# Generate a list of all unique problems found in MIMIC-III:\n",
    "query = 'MATCH (prob:Problem) RETURN collect(DISTINCT(prob.description))'\n",
    "problems = get_list(query)\n",
    "print(\"Number of items in list: \",len(problems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7f7e6d7-a7ac-4e4b-95de-8dfd8333084a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in list:  4526\n"
     ]
    }
   ],
   "source": [
    "# Generate a list of all unique prescriptions found in MIMIC-III:\n",
    "query = 'MATCH (rx:Prescriptions) RETURN collect(DISTINCT(rx.DRUG))'\n",
    "drugs = get_list(query)\n",
    "print(\"Number of items in list: \",len(drugs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55879194-9ae6-4cf7-925f-f831557c764f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in list:  305\n"
     ]
    }
   ],
   "source": [
    "# Generate a list of all unique labs which are flagged as abnormal at least once in MIMIC-III:\n",
    "query = '''\n",
    "MATCH (lab:Labevents)\n",
    "WHERE lab.FLAG = \"abnormal\"\n",
    "WITH collect(DISTINCT(lab.ITEMID)) AS abnormals\n",
    "MATCH (description:D_Labitems)\n",
    "WHERE description.ITEMID IN abnormals\n",
    "RETURN collect(description.LABEL)'''\n",
    "\n",
    "labs = get_list(query)\n",
    "print(\"Number of items in list: \",len(labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea777192-aad6-44dd-b0f7-7ed08a430be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in list:  9357\n"
     ]
    }
   ],
   "source": [
    "# Combine the lists for problems, prescriptions, and abnormal labs\n",
    "pubmed_query_list = problems + drugs + labs\n",
    "print(\"Number of items in list: \",len(pubmed_query_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "94d2fed2-c8bf-474f-b110-47cb1be80c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes a term, searches PubMed for that term, and returns a list of the \n",
    "# PMIDs of the articles found\n",
    "def find_pmid_list_for(term, max_result_count=1000):\n",
    "    esearch_query_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&retmax={retmax}&term={term}'.format(retmax=max_result_count, term=term)\n",
    "    response = requests.get(esearch_query_url)\n",
    "    content = response.content\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    try:\n",
    "        ids_str = soup.idlist.get_text()\n",
    "        ids_str = ids_str.replace('\\n',',')\n",
    "        ids_str = ids_str[1:-1] \n",
    "        ids_str = ids_str.split(',')\n",
    "        return ids_str\n",
    "    \n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9f66aa59-4fdd-4d56-ab55-f8f2ad43cc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in list:  1044253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform a pubmed search for each term that returns at most 1000 articles per query and add them to a set of PMIDs\n",
    "pmid_list = set()\n",
    "pbar = ProgressBar()\n",
    "for term in pbar(pubmed_query_list):\n",
    "    pmid_list.update(find_pmid_list_for(term, max_result_count=1000))\n",
    "print(\"Number of items in list: \",len(pmid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e43fc3a3-6987-486a-bdd3-e8c041db05f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25913168', '32671735', '34022190']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmid_list = list(pmid_list) # change pmid_list from a set to a list\n",
    "pmid_list = pmid_list[1:] # remove the item in the list, which is blank\n",
    "pmid_list[:3] # check to be sure the blank item was removed properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "311a00d1-57ac-457b-9b86-7427bea2f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pmid_list\n",
    "with open('MIMIC_pmid_list', 'wb') as fp:\n",
    "    pickle.dump(pmid_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f0e8aa9-a69e-445e-81b2-57b57734f4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in list:  1044252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['25913168', '32671735', '34022190']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the pmid_list from disc and check to be sure it still looks right\n",
    "with open ('MIMIC_pmid_list', 'rb') as fp:\n",
    "    saved_pmid_list = pickle.load(fp)\n",
    "\n",
    "print(\"Number of items in list: \",len(saved_pmid_list))\n",
    "saved_pmid_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338aa305-fab7-4e3a-b1bf-aba8d9bb17bc",
   "metadata": {},
   "source": [
    "To-Do:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abae7d9b-4eea-4692-8f24-e41377f8ec11",
   "metadata": {},
   "source": [
    "### 1-B. Run all the articles through GPT3 to extract entities and CAUSES/SYNONYM relationships.\n",
    "Define a set of functions that\n",
    "- take a batch of PubMed PMIDs\n",
    "- extract the articles\n",
    "- select the sentences which have causal statements\n",
    "- use the GPT3 API to extract causal relationships\n",
    "- store the causal relationships in a dataframe along with pmid and article's level of evidence\n",
    "- merge the entities in as Concept nodes. Merge the text of the GPT3-extracted concept against the UMLS Concept \"term\" property"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1237c54-4cdc-4d61-9844-62bb1f2199fe",
   "metadata": {},
   "source": [
    "## Reasoning Framework\n",
    "See [Reasoning_Framework.ipynb](Reasoning_Framework.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e064e9-8509-4a46-84de-dea662636334",
   "metadata": {},
   "source": [
    "### Present plans to the patient and update aversion scores based on their acceptance/rejection. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
